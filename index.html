<html>
  <head>
    <title>Image Uploader</title>
  </head>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@2.0.0/dist/tf.min.js"></script>

  <style>
    #image-container {
        width: 500px;
        height: 500px;
        border: 1px solid black;
        display: flex;
        align-items: center;
        justify-content: center;
    }

    #image-container img {
        max-width: 100%;
        max-height: 100%;
    }
  </style>
  <body>
    <h1>Resource Model Demo</h1>
    <br/>
    <h3>Mission</h3>
    <p>Make it easier for retailers to donate unsold food to local food banks.</p>
    <br/>
    <h3>Strategy</h3>
    <p>Leveraging tech to automate the collection of unsold food and notifying food banks. Examples include computer vision and AI to automate data entry and recommenders to better allocate donations.</p>
    <br/>
    <h3>Why this basic site?</h3>
    <p>
        Part of the requirements for Buildspace nights & weekends is to get the f*** off localhost. This past week we reapproached our expected user intereaction to be via a mobile app (mock designs to come). 
        To automate the data entry we cheated by taking the <a href="https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/5">MobileNet V2 model trained on imageNet 1K</a> and fine tuning it for different types of fruits and veggies using the <a href="https://www.kaggle.com/datasets/moltean/fruits">fruits-360 dataset</a>.
        This model is intended to run on a mobile device to classify produce as employees take it off the shelf. While our model seems to work we need your help to collect more images to build a better model!
        When you upload an image and provide a label it will get saved for future training. 
    </p>
    <br/>
    <form id="image-form">
      <input type="file" id="image-input" accept="image/*">
      <br/>
      
      <label for="produce">Produce Type:</label>
      <input type="text" id="produce" name="produce"><br><br>

      <button type="submit">Upload Image</button>
    </form>
    <div>
        <h4>Prediction: </h4><h5 id="prediction"></h4>
    </div>
    <div id="image-container"></div>
  </body>
</html>

<script>
    var model;
    const classes = ['apple',
                    'avocado',
                    'banana',
                    'blueberry',
                    'cauliflower',
                    'cherry',
                    'corn',
                    'cucumber',
                    'eggplant',
                    'grape',
                    'grapefruit',
                    'mango',
                    'onion',
                    'orange',
                    'papaya',
                    'peach',
                    'pear',
                    'pepper',
                    'pineapple',
                    'potato',
                    'strawberry',
                    'tomato',
                    'watermelon'];
    
    window.onload = async () => {
        model = await tf.loadGraphModel('/nights-weekend-demo/model.json');
    };

    function forecast(imgFile, produceType) {
        const predictionElem = document.querySelector("#prediction");

        const imageInput = new Image();
        console.log('reader.result:', imgFile);
        imageInput.src = imgFile;
        imageInput.onload = () => {
            // Convert the image to a Tensor.
            let imageTensor = tf.browser.fromPixels(imageInput);

            // You can now use the Tensor for machine learning tasks.
            let resizedTensorImage = tf.image.resizeBilinear(imageTensor, [224, 224]);
            resizedTensorImage = resizedTensorImage.reshape([-1, 224, 224, 3]);
            const predictions = model.predict(resizedTensorImage);
            const predictionIndex = predictions.argMax(axis=1).dataSync()[0];
            const prediction = classes[predictionIndex];
            
            console.log('predictions: ', predictions);
            console.log('prediction: ', prediction);
            predictionElem.innerText = prediction;
        };
    }

    async function logData(imgFile, produceType) {
        console.log('inside logData');
        // make call to api
        const endpoint = 'https://yimry0eqph.execute-api.us-east-1.amazonaws.com/DEV';
        const response = await fetch(endpoint, {
            method: 'POST',
            body: JSON.stringify({ produce: produceType }),
            headers: { 
                'Content-Type': 'application/json', 
                'access-control-allow-headers': 'Content-Type,X-Amz-Date,Authorization,X-Api-Key,X-Amz-Security-Token',
                'access-control-allow-methods': 'OPTIONS,POST',
                'access-control-allow-origin': 'https://ryanratm.github.io'
            }
        });

        console.log('response: ', response);

        // make put to url

    }

    document.addEventListener('DOMContentLoaded', () => {
        const form = document.querySelector('#image-form');
        const imageContainer = document.querySelector('#image-container');
        const produceType = document.querySelector("#produce").value;

        form.addEventListener('submit', (event) => {
            console.log('in event listener: ', produceType);
            event.preventDefault();

            if(produceType != undefined && produceType != "") {
                const file = document.querySelector('#image-input').files[0];
                const reader = new FileReader();

                reader.onloadend = () => {
                    imageContainer.innerHTML = '';
                    const img = document.createElement('img');
                    img.src = reader.result;
                    imageContainer.appendChild(img);

                    logData(reader.result, produceType); // file
                    forecast(reader.result, produceType);
                };
                reader.readAsDataURL(file);
            }
        });
    });
</script>
